{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74z_RfbLZyVf"
   },
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORMSX7cLcCd9"
   },
   "outputs": [],
   "source": [
    "# Returns EAR given eye landmarks\n",
    "def eye_aspect_ratio(eye):\n",
    "    # Compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "\n",
    "    # Compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # Return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zjk_sV_c5Il"
   },
   "outputs": [],
   "source": [
    "# Returns MAR given eye landmarks\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    # Compute the euclidean distances between the three sets\n",
    "    # of vertical mouth landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(mouth[13] - mouth[19])\n",
    "    B = np.linalg.norm(mouth[14] - mouth[18])\n",
    "    C = np.linalg.norm(mouth[15] - mouth[17])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal\n",
    "    # mouth landmarks (x, y)-coordinates\n",
    "    D = np.linalg.norm(mouth[12] - mouth[16])\n",
    "\n",
    "    # Compute the mouth aspect ratio\n",
    "    mar = (A + B + C) / (2 * D)\n",
    "\n",
    "    # Return the mouth aspect ratio\n",
    "    return mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1gyiz16ZyVl"
   },
   "outputs": [],
   "source": [
    "# Thresholds and consecutive frame length for triggering action.\n",
    "MOUTH_AR_THRESH = 0.18\n",
    "MOUTH_AR_CONSECUTIVE_FRAMES = 4\n",
    "EYE_AR_THRESH = 0.17\n",
    "EYE_AR_CONSECUTIVE_FRAMES = 4\n",
    "WINK_AR_DIFF_THRESH = 0.04\n",
    "WINK_AR_CLOSE_THRESH = 0.19\n",
    "WINK_CONSECUTIVE_FRAMES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8GSaRiGZyVr"
   },
   "outputs": [],
   "source": [
    "# Initialize the frame counters for each action as well as \n",
    "# booleans used to indicate if action is performed or not\n",
    "stop_counter = 0\n",
    "left_counter = 0\n",
    "right_counter = 0\n",
    "forward_counter=0\n",
    "anchor_point = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZ3-8V-zZyVw"
   },
   "outputs": [],
   "source": [
    "WHITE_COLOR = (255, 255, 255)\n",
    "YELLOW_COLOR = (0, 255, 255)\n",
    "RED_COLOR = (0, 0, 255)\n",
    "GREEN_COLOR = (0, 255, 0)\n",
    "BLUE_COLOR = (255, 0, 0)\n",
    "BLACK_COLOR = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "positionOfText = (5,100)\n",
    "fontScale = 1\n",
    "lineType = 2\n",
    "fontColor = GREEN_COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "9M6crYxpZyV1",
    "outputId": "75e21f5e-3b0d-4eee-a9f5-bd7ac62b4ddb"
   },
   "outputs": [],
   "source": [
    "# Initialize Dlib's face detector and then create\n",
    "# the facial landmark predictor\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Qw9tXliZyV6"
   },
   "outputs": [],
   "source": [
    "# Grab the indexes of the facial landmarks for the left and\n",
    "# right eye, nose and mouth respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3IU8o9sZyV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break applied\n",
      "break applied\n",
      "break applied\n",
      "break applied\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "resolution_w = 1366\n",
    "resolution_h = 768\n",
    "cam_w = 640\n",
    "cam_h = 480\n",
    "unit_w = resolution_w / cam_w\n",
    "unit_h = resolution_h / cam_h\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # load the input image and convert it to grayscale\n",
    "    _, frame = cap.read()\n",
    "    # detect faces in the grayscale image\n",
    "    frame = imutils.resize(frame, width=cam_w, height=cam_h)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    if len(rects)>0:\n",
    "        rect=rects[0]\n",
    "        \n",
    "    else:\n",
    "        cv2.imshow(\"Output\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        continue\n",
    "    \n",
    "    # Determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "    for (x, y) in shape:\n",
    "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "    \n",
    "    mouth = shape[mStart:mEnd]\n",
    "    leftEye = shape[lStart:lEnd]\n",
    "    rightEye = shape[rStart:rEnd]\n",
    "    nose = shape[nStart:nEnd]\n",
    "    \n",
    "\n",
    "    # Average the mouth aspect ratio together for both eyes\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    diff_ear = np.abs(leftEAR - rightEAR)\n",
    "    \n",
    "    \n",
    "    # Compute the convex hull for the left and right eye, then\n",
    "    # visualize each of the eyes\n",
    "    mouthHull = cv2.convexHull(mouth)\n",
    "    leftEyeHull = cv2.convexHull(leftEye)\n",
    "    rightEyeHull = cv2.convexHull(rightEye)\n",
    "    cv2.drawContours(frame, [mouthHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, YELLOW_COLOR, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for (x, y) in np.concatenate((mouth, leftEye, rightEye), axis=0):\n",
    "        cv2.circle(frame, (x, y), 2, GREEN_COLOR, -1)\n",
    "        \n",
    "    # Check to see if the eye aspect ratio is below the blink\n",
    "    # threshold, and if so, increment the blink frame counter\n",
    "    # print(\"Code here\")\n",
    "    # print(diff_ear,WINK_AR_DIFF_THRESH)\n",
    "    \n",
    "    #print('mar value is' ,mar)\n",
    "    \n",
    "    if mar > MOUTH_AR_THRESH:\n",
    "        stop_counter = stop_counter + 1\n",
    "        #print('stop counter value is',stop_counter)\n",
    "        if stop_counter > MOUTH_AR_CONSECUTIVE_FRAMES:\n",
    "            print('break applied')\n",
    "            \n",
    "            cv2.putText(frame,'break applied', positionOfText, font, fontScale,fontColor,lineType)\n",
    "            stop_counter = 0\n",
    "    \n",
    "    if diff_ear > WINK_AR_DIFF_THRESH:\n",
    "        #print(leftEAR,rightEAR)\n",
    "        if leftEAR < rightEAR:\n",
    "            if leftEAR < EYE_AR_THRESH:\n",
    "                left_counter = left_counter + 1\n",
    "                \n",
    "                #print('left counter value is',left_counter)\n",
    "                if left_counter > WINK_CONSECUTIVE_FRAMES:\n",
    "                    print('move left')\n",
    "                    \n",
    "                    cv2.putText(frame,'turn left', positionOfText, font, fontScale,fontColor,lineType)\n",
    "                    left_counter = 0\n",
    "\n",
    "        elif leftEAR > rightEAR:\n",
    "            # print(\"Shown Below \",rightEAR)\n",
    "            if rightEAR < EYE_AR_THRESH:\n",
    "                right_counter = right_counter+1\n",
    "                   \n",
    "                #print('right counter value is',right_counter)\n",
    "                if right_counter > WINK_CONSECUTIVE_FRAMES:\n",
    "                    print('move right')\n",
    "                    \n",
    "                    cv2.putText(frame,'turn right', positionOfText, font, fontScale,fontColor,lineType)\n",
    "                    right_counter = 0\n",
    "\n",
    "    else:\n",
    "      if ear <= EYE_AR_THRESH:\n",
    "            forward_counter = forward_counter+ 1\n",
    "            \n",
    "            #print('forward counter value is',forward_counter)\n",
    "            if forward_counter > EYE_AR_CONSECUTIVE_FRAMES:\n",
    "                print('move forward')\n",
    "                \n",
    "                cv2.putText(frame,'move forward', positionOfText, font, fontScale,fontColor,lineType)\n",
    "                forward_counter = 0\n",
    "                \n",
    "    \n",
    "#     print(\"Image Shown Here\",frame)\n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "motion-controller.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
