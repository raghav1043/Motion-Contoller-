{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "operate wheelchair through facial expressions\n",
    "\n",
    "forward :- open mouth <br/>\n",
    "stop :- closed eyes <br/>\n",
    "left turn :- kiss <br/>\n",
    "right turn :- raised eyebrows <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds and consecutive frame length for triggering action.\n",
    "mouth_ar_thresh = 0.24\n",
    "mouth_ar_consecutive_frames = 6\n",
    "eye_ar_thresh = 0.19\n",
    "eye_ar_consecutive_frames = 4\n",
    "raised_eyebrows_thresh = 210\n",
    "raised_eyebrows_consecutive_frames = 4\n",
    "kiss_thresh = 55\n",
    "kiss_consecutive_frames = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the frame counters for each action as well as \n",
    "# booleans used to indicate if action is performed or not\n",
    "stop_counter = 0\n",
    "left_counter = 0\n",
    "right_counter = 0\n",
    "forward_counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_color = (255, 255, 255)\n",
    "yellow_color = (0, 255, 255)\n",
    "red_color = (0, 0, 255)\n",
    "green_color = (0, 255, 0)\n",
    "blue_color = (255, 0, 0)\n",
    "black_color = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dlib's face detector and then create\n",
    "# the facial landmark predictor\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For dlibâ€™s 68-point facial landmark detector:\n",
    "\n",
    "(leStart, leEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(reStart, reEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(jStart, jEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"jaw\"]\n",
    "(lebStart, lebEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eyebrow\"]\n",
    "(rebStart, rebEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eyebrow\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for eye blink detection code\n",
    "\n",
    "# Returns eye_aspect_ratio given eye landmarks\n",
    "def eye_aspect_ratio(eye):\n",
    "    # Compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "\n",
    "    # Compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # Return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for open mouth detection code\n",
    "\n",
    "# Returns mouth_aspect_ratio given eye landmarks\n",
    "def open_mouth_aspect_ratio(mouth):\n",
    "    # Compute the euclidean distances between the three sets\n",
    "    # of vertical mouth landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(mouth[13] - mouth[19])\n",
    "    B = np.linalg.norm(mouth[14] - mouth[18])\n",
    "    C = np.linalg.norm(mouth[15] - mouth[17])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal\n",
    "    # mouth landmarks (x, y)-coordinates\n",
    "    D = np.linalg.norm(mouth[12] - mouth[16])\n",
    "\n",
    "    # Compute the mouth aspect ratio\n",
    "    omar = (A + B + C) / (2 * D)\n",
    "\n",
    "    # Return the mouth aspect ratio\n",
    "    return omar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for raised eyeborws detection code\n",
    "\n",
    "# Returns raised_eyebrows_aspect_ratio given eye landmarks\n",
    "def raised_eyebrows_aspect_ratio(eyebrows,eye):\n",
    "    # Compute the euclidean distances between the landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(eyebrows[1] - mouth[1])\n",
    "    B = np.linalg.norm(eyebrows[3] - mouth[2])\n",
    "\n",
    "    # Compute the mouth aspect ratio\n",
    "    rear = (A + B)\n",
    "\n",
    "    # Return the raised eyebrows aspect ratio\n",
    "    return rear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for kiss detection code\n",
    "\n",
    "# Returns kiss_mouth_aspect_ratio given eye landmarks\n",
    "def kiss_mouth_aspect_ratio(mouth):\n",
    "    # Compute the euclidean distance between the horizontal\n",
    "    # mouth landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(mouth[0] - mouth[6])\n",
    "\n",
    "    # Compute the mouth aspect ratio\n",
    "    kmar = A\n",
    "\n",
    "    # Return the mouth aspect ratio\n",
    "    return kmar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    # load the input image and convert it to grayscale\n",
    "    _, frame = cap.read()\n",
    "    # detect faces in the grayscale image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    if len(rects)>0:\n",
    "        rect=rects[0]\n",
    "        \n",
    "    else:\n",
    "        cv2.imshow(\"Output\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        continue\n",
    "    \n",
    "    # Determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)  \n",
    "    \n",
    "    mouth = shape[mStart:mEnd]\n",
    "    leftEye = shape[leStart:leEnd]\n",
    "    rightEye = shape[reStart:reEnd]\n",
    "    leftEyebrow = shape[lebStart:lebEnd]\n",
    "    rightEyebrow = shape[rebStart : rebEnd]\n",
    "    \n",
    "    \n",
    "    #open mouth aspect ratio\n",
    "    omar = open_mouth_aspect_ratio(mouth)\n",
    "    \n",
    "    # average eye aspect ratio\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    \n",
    "    # average raised eyebrows aspect ratio\n",
    "    leftREAR = raised_eyebrows_aspect_ratio(leftEyebrow,leftEye)\n",
    "    rightREAR = raised_eyebrows_aspect_ratio(rightEyebrow,rightEye)\n",
    "    rear = (leftREAR + rightREAR) / 2.0\n",
    "    \n",
    "    # kiss mouth aspect ratio\n",
    "    kmar = kiss_mouth_aspect_ratio(mouth)\n",
    "    \n",
    "\n",
    "    # Compute the convex hull for the left and right eye, then\n",
    "    # visualize each of the eyes\n",
    "    mouthHull = cv2.convexHull(mouth)\n",
    "    leftEyeHull = cv2.convexHull(leftEye)\n",
    "    rightEyeHull = cv2.convexHull(rightEye)\n",
    "    cv2.drawContours(frame, [mouthHull], -1, yellow_color, 1)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, yellow_color, 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, yellow_color, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for (x, y) in np.concatenate((mouth, leftEye, rightEye, leftEyebrow, rightEyebrow), axis=0):\n",
    "        cv2.circle(frame, (x, y), 2, green_color, -1)\n",
    "    \n",
    "    \n",
    "    if omar > mouth_ar_thresh:\n",
    "        forward_counter += 1\n",
    "        \n",
    "        if forward_counter > mouth_ar_consecutive_frames:\n",
    "            cv2.putText(frame, 'move forward', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0,255), 2)\n",
    "            forward_counter = 0\n",
    "            \n",
    "    elif ear < eye_ar_thresh:\n",
    "        stop_counter += 1\n",
    "        \n",
    "        if stop_counter > eye_ar_consecutive_frames:\n",
    "            cv2.putText(frame, 'stop', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0,255), 2)\n",
    "            stop_counter = 0\n",
    "            \n",
    "    elif kmar < kiss_thresh:\n",
    "        left_counter += 1\n",
    "        \n",
    "        if left_counter > kiss_consecutive_frames:\n",
    "            cv2.putText(frame, 'move left ', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0,255), 2)\n",
    "            left_counter = 0        \n",
    "        \n",
    "    elif rear > raised_eyebrows_thresh:\n",
    "        right_counter += 1\n",
    "        \n",
    "        if right_counter > raised_eyebrows_consecutive_frames:\n",
    "            cv2.putText(frame, 'move right', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0,255), 2)\n",
    "            right_counter = 0\n",
    "                           \n",
    "\n",
    "#     print(\"Image Shown Here\",frame)\n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
